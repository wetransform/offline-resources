import java.time.*
import java.time.temporal.*
import eu.esdihumboldt.util.config.*

buildscript {
  repositories {
    // mavenLocal()
    maven {
      url 'https://artifactory.wetransform.to/artifactory/libs-release-local'
    }
    maven {
      url 'https://artifactory.wetransform.to/artifactory/libs-snapshot-local'
    }
    jcenter()
  }
  dependencies {
    // for Config class
    classpath 'eu.esdihumboldt.hale:eu.esdihumboldt.util.config:3.5.0'
    // for XMLSchemaUpdater (depends on https://github.com/halestudio/hale/pull/731)
    classpath 'eu.esdihumboldt.hale:eu.esdihumboldt.hale.common.core:4.0.0-SNAPSHOT'
  }
}

plugins {
  id 'de.undercouch.download' version '3.4.3'
}

ext {
  resourcesFolder = file('resources')
  hostsFolder = new File(resourcesFolder, 'hosts')
  jarFolder = new File(buildDir, 'jars')
  now = LocalDate.now()
}

defaultTasks 'downloads', 'jars', 'publish'

/*
 * Helper classes and task definitions
 */

class MetadataHelper {
  static final METADATA_DIR_NAME = '.metadata'

  private final Project project
  private final File parentDir
  private final File metadataDir
  MetadataHelper(Project project, File parentDir) {
    this.project = project
    this.parentDir = parentDir
    this.metadataDir = new File(parentDir, METADATA_DIR_NAME)
  }

  def withConfig(Closure configure) {
    def configFile = new File(metadataDir, 'metadata.yml')
    configFile.parentFile.mkdirs()
    def config = configFile.exists() ? ConfigYaml.load(configFile) : new Config()
    // unexpectedly, when accessing config, instead of getAt get is used
    // when accessing config -> thus we interact with the map instead
    def map = config.asMap()
    def result = configure(map)
    result
  }

  def updateConfig(Closure configure) {
    def configFile = new File(metadataDir, 'metadata.yml')
    configFile.parentFile.mkdirs()
    def config = configFile.exists() ? ConfigYaml.load(configFile) : new Config()
    // unexpectedly, when accessing config, instead of getAt get is used
    // when accessing config -> thus we interact with the map instead
    def map = config.asMap()
    def result = configure(map)
    ConfigYaml.save(config, configFile)
    result
  }

  void setVersion() {
    int year = project.ext.now.getYear();
    int month = project.ext.now.getMonthValue();
    int day = project.ext.now.getDayOfMonth();

    def version = "$year.$month.$day" as String

    updateConfig {
      it.year = year
      it.version = version
    }
  }

  String getVersion() {
    def version = withConfig {
      it.version
    }
    if (!version) {
      // default to year snapshot
      int year = project.ext.now.getYear();
      "${year}-SNAPSHOT"
    }
    else {
      version
    }
  }

  String getSnapshot() {
    def version = withConfig {
      it.year
    }
    if (!version) {
      // default to current year
      int year = project.ext.now.getYear();
      "${year}-SNAPSHOT"
    }
    else {
      "${version}-SNAPSHOT"
    }
  }

  void generateJar(File sourceFolder, File targetFolder, String name) {
    def version = getVersion()

    // assemble different publication versions
    def fileVersions = new HashSet<>()
    fileVersions << version
    fileVersions << getSnapshot()
    fileVersions << 'CURRENT-SNAPSHOT'

    fileVersions.each { fileVersion ->

      def jarFile = new File(targetFolder, "${name}_${fileVersion}.jar")

      // OSGi symbolic name
      def symbolicName = "to.wetransform.offline-resources.${name}"

      //TODO include OSGi/hale related stuff?

      // build jar
      project.ant.jar(destfile: jarFile) {
        fileset(dir: sourceFolder, includes: '**/*')
        manifest {
          attribute(name: 'Implementation-Version', value: version)
          // OSGi related metadata
          attribute(name: 'Bundle-Version', value: fileVersion)
          attribute(name: 'Bundle-Name', value: "Offline Resource bundle ${name}")
          attribute(name: 'Bundle-ManifestVersion', value: 2)
          attribute(name: 'Bundle-SymbolicName', value: "$symbolicName;singleton:=true")
        }
      }

    }
  }
}

class ResourcesArchiveTask extends DefaultTask {
  // the host that the resource bundle mirrors resources from
  def host
  // the remote URL to retrieve the resource ZIP archive from
  def archiveUrl

  @TaskAction
  def downloadAndExtract() {
    assert host
    assert archiveUrl

    // download archive
    File tmpSchemas = new File(temporaryDir, 'schemas.zip')
    project.download {
      src archiveUrl
      dest tmpSchemas
      onlyIfModified true
    }

    File targetDir = project.file("${project.ext.hostsFolder}/$host")
    // delete folder
    targetDir.deleteDir()
    targetDir.mkdirs()

    def md = new MetadataHelper(project, targetDir)
    //XXX only if there were changes?
    md.setVersion()

    project.copy {
      // exclude Zip files
      exclude('**/*.zip')

      from project.zipTree(tmpSchemas)
      into targetDir
    }
  }
}

class XmlSchemaDownloadTask extends DefaultTask {
  // the location of the remote schema
  def schemaUrl
  // the name if the schema
  def schemaName
  // the name of the resource group
  def resourceGroup

  @TaskAction
  def download() {
    assert schemaUrl
    assert schemaName
    assert resourceGroup

    File schemaTargetDir = project.file("${project.ext.resourcesFolder}/$resourceGroup/$schemaName")
    schemaTargetDir.deleteDir()
    schemaTargetDir.mkdirs()

    File schemaFile = new File(schemaTargetDir, 'schema.xsd')

    // download archive
    project.download {
      src schemaUrl
      dest schemaFile
      overwrite true
    }

    def md = new MetadataHelper(project, schemaTargetDir)
    md.setVersion()
    md.withConfig {
      it.originalLocation = schemaUrl as String
    }

    // update schema file and download references
    eu.esdihumboldt.hale.common.core.io.project.util.XMLSchemaUpdater.update(
      schemaFile, URI.create(schemaUrl), true, null)
  }
}


/*
 * Download tasks
 */

/**
 * Aggregation task for downloads
 */
task('downloads')

/**
 * Schemas from schemas.opengis.net
 */
task opengisSchemas(type: ResourcesArchiveTask) {
  host = "schemas.opengis.net"
  archiveUrl = "http://schemas.opengis.net/SCHEMAS_OPENGIS_NET.zip"
}
tasks.downloads.dependsOn(opengisSchemas)

/**
 * Schemas for metadata validation:
 *
 * http://standards.iso.org/ittf/PubliclyAvailableStandards/ISO_19139_Schemas/gmd/gmd.xsd
 * http://www.isotc211.org/2005/gmd/gmd.xsd
 * http://schemas.opengis.net/csw/2.0.2/profiles/apiso/1.0.0/apiso.xsd
 */
task metadataIso(type: XmlSchemaDownloadTask) {
  schemaUrl = 'http://standards.iso.org/ittf/PubliclyAvailableStandards/ISO_19139_Schemas/gmd/gmd.xsd'
  schemaName = 'ISO_19139_GMD'
  resourceGroup = 'metadata-schemas'
}
tasks.downloads.dependsOn(metadataIso)

task metadataIsoTC211(type: XmlSchemaDownloadTask) {
  schemaUrl = 'http://www.isotc211.org/2005/gmd/gmd.xsd'
  schemaName = 'ISO_TC211_GMD'
  resourceGroup = 'metadata-schemas'
}
tasks.downloads.dependsOn(metadataIsoTC211)

task metadataCSW2(type: XmlSchemaDownloadTask) {
  schemaUrl = 'http://schemas.opengis.net/csw/2.0.2/profiles/apiso/1.0.0/apiso.xsd'
  schemaName = 'CSW_2_APISO'
  resourceGroup = 'metadata-schemas'
}
tasks.downloads.dependsOn(metadataCSW2)


/*
 * Processing tasks
 */

/**
 * Task for creating resource JARs for use in Java applications
 */
task(jars) {

}.doLast {

  /*
   * JARs for host folders
   */
  def files = project.ext.hostsFolder.listFiles()
  project.logger.info("Identified ${files.size()} potential host JARs")

  jarFolder.deleteDir()
  jarFolder.mkdirs()

  def tmpJarFolder = new File(temporaryDir, 'jar')

  files.each { File file ->
    // for each host folder
    if (file.isDirectory()) {
      println "Creating resources JARs for host ${file.name}"

      // prepare structure for inside JAR
      // use sub-directories to avoid confusion w/ other resources
      tmpJarFolder.deleteDir()
      tmpJarFolder.mkdirs()

      def resFolder = new File(tmpJarFolder, "to/wetransform/offline-resources/hosts/${file.name}")
      resFolder.mkdirs()

      copy {
        from file
        into resFolder

        exclude "${MetadataHelper.METADATA_DIR_NAME}/**"
      }

      def md = new MetadataHelper(project, file)
      md.generateJar(tmpJarFolder, jarFolder, file.name)
    }
  }

  /*
   * JARs for other folders
   */
  files = project.ext.resourcesFolder.listFiles()

  files.each { File file ->
    if (file.isDirectory() && !file.name.equals('hosts')) {
      println "Creating resources JARs for ${file.name}"

      // prepare structure for inside JAR
      // use sub-directories to avoid confusion w/ other resources
      tmpJarFolder.deleteDir()
      tmpJarFolder.mkdirs()

      def resFolder = new File(tmpJarFolder, "to/wetransform/offline-resources/${file.name}")
      resFolder.mkdirs()

      copy {
        from file
        into resFolder

        exclude "${MetadataHelper.METADATA_DIR_NAME}/**"
      }
      
      def md = new MetadataHelper(project, file)
      md.generateJar(tmpJarFolder, jarFolder, file.name)
    }
  }

}

/**
 * Task that publishes all Jars to artifactory.
 */
task('publishJars', type: GradleBuild) {
  buildFile = file('publish.gradle')

  startParameter.projectProperties.publications = jarFolder.getAbsolutePath()

  tasks = ['publish']
}

/**
 * Task for creating resource bundles used by hale
 */
task haleResourceBundles() {
  //TODO separate task or adapt hale functionality to work with JARs built in jars task?
}
